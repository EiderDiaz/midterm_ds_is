{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3. Using the supernova.txt data available in https://web.stanford.edu/~hastie/CASI/data.html, predict the magnitude of observations 5,10,15, 25 and 30 fitting a model using all other observations. The candidate models that you must fit are: a) Linear Model using OLS, b) Linear Model using ridge and your choice of Lambda, c) Decision Tree Regressor with your choice of max_depth. Which of these three has the smallest MSE on observations 5,10,15,25 and 30? (30 points). Which are the most relevant variables to predict magnitude according to each model?__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other to answered the two questions, which model has the smallest MSE on observations 5,10,15,25 and 30? and which are the most relevant variable to predict magnitude according to each model?, we will do the three models and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as cm\n",
    "\n",
    "from statsmodels.regression import linear_model\n",
    "from statsmodels.regression.linear_model import OLS #ordinary least squares\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from statsmodels.discrete.discrete_model import Poisson\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from scipy.special import gammaln\n",
    "from scipy.optimize import minimize\n",
    "from scipy import integrate\n",
    "from sklearn.linear_model import RidgeCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step_1__: Reading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        E1     E2     E3     E4     E5     E6     E7     E8     E9    E10  \\\nSN1 -0.839 -0.927  0.320  0.176 -0.676 -1.272  0.342 -0.427 -0.016 -0.298   \nSN2 -1.892 -0.455  2.407  0.766 -0.944 -1.527  0.088  0.261  0.185 -0.537   \nSN3  0.264 -0.803  1.141 -0.863  0.685 -0.354 -1.038 -1.098 -1.319 -1.695   \nSN4 -0.083  1.023 -0.206 -1.115 -0.863  0.715  0.616  0.564  0.615 -0.488   \nSN5  0.411 -0.807 -0.129  1.315 -0.647  0.299 -0.822 -1.534 -1.486 -1.087   \n\n     Magnitude  \nSN1     -0.543  \nSN2      2.124  \nSN3     -0.217  \nSN4      0.946  \nSN5     -3.746  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>E1</th>\n      <th>E2</th>\n      <th>E3</th>\n      <th>E4</th>\n      <th>E5</th>\n      <th>E6</th>\n      <th>E7</th>\n      <th>E8</th>\n      <th>E9</th>\n      <th>E10</th>\n      <th>Magnitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>SN1</th>\n      <td>-0.839</td>\n      <td>-0.927</td>\n      <td>0.320</td>\n      <td>0.176</td>\n      <td>-0.676</td>\n      <td>-1.272</td>\n      <td>0.342</td>\n      <td>-0.427</td>\n      <td>-0.016</td>\n      <td>-0.298</td>\n      <td>-0.543</td>\n    </tr>\n    <tr>\n      <th>SN2</th>\n      <td>-1.892</td>\n      <td>-0.455</td>\n      <td>2.407</td>\n      <td>0.766</td>\n      <td>-0.944</td>\n      <td>-1.527</td>\n      <td>0.088</td>\n      <td>0.261</td>\n      <td>0.185</td>\n      <td>-0.537</td>\n      <td>2.124</td>\n    </tr>\n    <tr>\n      <th>SN3</th>\n      <td>0.264</td>\n      <td>-0.803</td>\n      <td>1.141</td>\n      <td>-0.863</td>\n      <td>0.685</td>\n      <td>-0.354</td>\n      <td>-1.038</td>\n      <td>-1.098</td>\n      <td>-1.319</td>\n      <td>-1.695</td>\n      <td>-0.217</td>\n    </tr>\n    <tr>\n      <th>SN4</th>\n      <td>-0.083</td>\n      <td>1.023</td>\n      <td>-0.206</td>\n      <td>-1.115</td>\n      <td>-0.863</td>\n      <td>0.715</td>\n      <td>0.616</td>\n      <td>0.564</td>\n      <td>0.615</td>\n      <td>-0.488</td>\n      <td>0.946</td>\n    </tr>\n    <tr>\n      <th>SN5</th>\n      <td>0.411</td>\n      <td>-0.807</td>\n      <td>-0.129</td>\n      <td>1.315</td>\n      <td>-0.647</td>\n      <td>0.299</td>\n      <td>-0.822</td>\n      <td>-1.534</td>\n      <td>-1.486</td>\n      <td>-1.087</td>\n      <td>-3.746</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "supernova_data = pd.read_table('supernova.txt',sep=r'\\s+')\n",
    "supernova_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We separate the \n",
    "supernova_train = supernova_data.drop(['SN5','SN10','SN15','SN25','SN30'])\n",
    "supernova_predict = supernova_data.drop(['SN1','SN2','SN3','SN4','SN6','SN7','SN8',\n",
    "                                         'SN9','SN11','SN12','SN13','SN14','SN16',\n",
    "                                         'SN17','SN18','SN19','SN20','SN21','SN22',\n",
    "                                         'SN23', 'SN24','SN26','SN27','SN28','SN29',\n",
    "                                        'SN31','SN32','SN33','SN34','SN35','SN36',\n",
    "                                         'SN37','SN38','SN39'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notice that:\n",
    "In order to mantain a coherence in the model, we will center and scale respect one of the sets, the supernova_train set and we are going to train our model with that data. Then the supernova_predict set would be scaled and use in the model to see how it works. The scaling and center would help us to see the importance in the coming features, our inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the ten predictor variables are quite varying and not on same scales, we'll need to center and scale them\n",
    "E1_mean,E1_std=supernova_train['E1'].mean(),supernova_train['E1'].std()\n",
    "E2_mean,E2_std=supernova_train['E2'].mean(),supernova_train['E2'].std()\n",
    "E3_mean,E3_std=supernova_train['E3'].mean(),supernova_train['E3'].std()\n",
    "E4_mean,E4_std=supernova_train['E4'].mean(),supernova_train['E4'].std()\n",
    "E5_mean,E5_std=supernova_train['E5'].mean(),supernova_train['E5'].std()\n",
    "E6_mean,E6_std=supernova_train['E6'].mean(),supernova_train['E6'].std()\n",
    "E7_mean,E7_std=supernova_train['E7'].mean(),supernova_train['E7'].std()\n",
    "E8_mean,E8_std=supernova_train['E8'].mean(),supernova_train['E8'].std()\n",
    "E9_mean,E9_std=supernova_train['E9'].mean(),supernova_train['E9'].std()\n",
    "E10_mean,E10_std=supernova_train['E10'].mean(),supernova_train['E10'].std()\n",
    "\n",
    "# Center and scale train respect train\n",
    "supernova_train['E1']=(supernova_train['E1']-E1_mean)/E1_std\n",
    "supernova_train['E2']=(supernova_train['E2']-E2_mean)/E2_std\n",
    "supernova_train['E3']=(supernova_train['E3']-E3_mean)/E3_std\n",
    "supernova_train['E4']=(supernova_train['E4']-E4_mean)/E4_std\n",
    "supernova_train['E5']=(supernova_train['E5']-E5_mean)/E5_std\n",
    "supernova_train['E6']=(supernova_train['E6']-E6_mean)/E6_std\n",
    "supernova_train['E7']=(supernova_train['E7']-E7_mean)/E7_std\n",
    "supernova_train['E8']=(supernova_train['E8']-E8_mean)/E8_std\n",
    "supernova_train['E9']=(supernova_train['E9']-E9_mean)/E9_std\n",
    "supernova_train['E10']=(supernova_train['E10']-E10_mean)/E10_std\n",
    "\n",
    "# Now we center and scale for the predict set respect to train set\n",
    "supernova_predict['E1']=(supernova_predict['E1']-E1_mean)/E1_std\n",
    "supernova_predict['E2']=(supernova_predict['E2']-E2_mean)/E2_std\n",
    "supernova_predict['E3']=(supernova_predict['E3']-E3_mean)/E3_std\n",
    "supernova_predict['E4']=(supernova_predict['E4']-E4_mean)/E4_std\n",
    "supernova_predict['E5']=(supernova_predict['E5']-E5_mean)/E5_std\n",
    "supernova_predict['E6']=(supernova_predict['E6']-E6_mean)/E6_std\n",
    "supernova_predict['E7']=(supernova_predict['E7']-E7_mean)/E7_std\n",
    "supernova_predict['E8']=(supernova_predict['E8']-E8_mean)/E8_std\n",
    "supernova_predict['E9']=(supernova_predict['E9']-E9_mean)/E9_std\n",
    "supernova_predict['E10']=(supernova_predict['E10']-E10_mean)/E10_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's create the columns for the predictions to visualize the predicted values at the end\n",
    "supernova_predict['Prediction OLS'] = 1\n",
    "supernova_predict['Prediction Ridge'] = 1\n",
    "supernova_predict['Prediction Tree'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      const        E1        E2        E3        E4        E5        E6  \\\nSN5     1.0  0.481631 -0.794486 -0.183682  1.559922 -0.569026  0.377266   \nSN10    1.0 -1.673576 -0.780025 -0.146156 -0.517614  0.271401 -0.160014   \nSN15    1.0  1.496996  2.484078 -1.995814 -1.805006  0.405950  2.723178   \nSN25    1.0  0.770707  0.345884  0.322925  3.186758  1.079697 -0.785799   \nSN30    1.0  1.218208  0.268414 -0.191582  0.191927  1.959284  0.415791   \n\n            E7        E8        E9       E10  \nSN5  -0.855366 -1.565895 -1.502760 -1.049453  \nSN10  0.713097 -0.199871 -0.261702 -0.214794  \nSN15  2.301427  0.820211  0.386363  0.572339  \nSN25 -1.095863 -0.282661  0.691219  1.674325  \nSN30 -0.901374 -0.880912 -0.928451  0.062435  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>const</th>\n      <th>E1</th>\n      <th>E2</th>\n      <th>E3</th>\n      <th>E4</th>\n      <th>E5</th>\n      <th>E6</th>\n      <th>E7</th>\n      <th>E8</th>\n      <th>E9</th>\n      <th>E10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>SN5</th>\n      <td>1.0</td>\n      <td>0.481631</td>\n      <td>-0.794486</td>\n      <td>-0.183682</td>\n      <td>1.559922</td>\n      <td>-0.569026</td>\n      <td>0.377266</td>\n      <td>-0.855366</td>\n      <td>-1.565895</td>\n      <td>-1.502760</td>\n      <td>-1.049453</td>\n    </tr>\n    <tr>\n      <th>SN10</th>\n      <td>1.0</td>\n      <td>-1.673576</td>\n      <td>-0.780025</td>\n      <td>-0.146156</td>\n      <td>-0.517614</td>\n      <td>0.271401</td>\n      <td>-0.160014</td>\n      <td>0.713097</td>\n      <td>-0.199871</td>\n      <td>-0.261702</td>\n      <td>-0.214794</td>\n    </tr>\n    <tr>\n      <th>SN15</th>\n      <td>1.0</td>\n      <td>1.496996</td>\n      <td>2.484078</td>\n      <td>-1.995814</td>\n      <td>-1.805006</td>\n      <td>0.405950</td>\n      <td>2.723178</td>\n      <td>2.301427</td>\n      <td>0.820211</td>\n      <td>0.386363</td>\n      <td>0.572339</td>\n    </tr>\n    <tr>\n      <th>SN25</th>\n      <td>1.0</td>\n      <td>0.770707</td>\n      <td>0.345884</td>\n      <td>0.322925</td>\n      <td>3.186758</td>\n      <td>1.079697</td>\n      <td>-0.785799</td>\n      <td>-1.095863</td>\n      <td>-0.282661</td>\n      <td>0.691219</td>\n      <td>1.674325</td>\n    </tr>\n    <tr>\n      <th>SN30</th>\n      <td>1.0</td>\n      <td>1.218208</td>\n      <td>0.268414</td>\n      <td>-0.191582</td>\n      <td>0.191927</td>\n      <td>1.959284</td>\n      <td>0.415791</td>\n      <td>-0.901374</td>\n      <td>-0.880912</td>\n      <td>-0.928451</td>\n      <td>0.062435</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#This would be used for the OLS and Ridge\n",
    "x = add_constant(supernova_predict.drop(['Magnitude','Prediction OLS','Prediction Ridge','Prediction Tree'], axis=1))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Linear Regression with OLS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having reagind the data, we will just need to apply the OLS for our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = ['E1','E2','E3','E4','E5','E6','E7','E8','E9','E10']\n",
    "supernova_OLS = OLS(supernova_train['Magnitude'], add_constant(supernova_train[x_cols])).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We insert the predicted values in the table\n",
    "supernova_predict['Prediction OLS'] = supernova_OLS.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we used cross validation to find the best alpha for our Ridge Regression and have our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "supernova_skR = RidgeCV(alphas=[0.09,0.1,0.11,0.12,0.13,0.14,0.15]).fit(add_constant(supernova_train[x_cols]),supernova_train['Magnitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The best alpha with cross validation is 0.15\n"
    }
   ],
   "source": [
    "model_cv = supernova_skR.fit(add_constant(supernova_train[x_cols]),supernova_train['Magnitude'])\n",
    "alp=model_cv.alpha_\n",
    "print('The best alpha with cross validation is',alp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([ 0.14623719, -0.52533127,  0.57661627, -0.10647332, -0.0411362 ,\n        0.03182501, -0.36276359,  0.74191783, -0.21686775,  0.53432215,\n       -0.00714745])"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "supernova_ridge = linear_model.OLS(supernova_train['Magnitude'], add_constant(supernova_train[x_cols])).fit_regularized(alpha=alp/supernova_train.shape[0], L1_wt=0)\n",
    "#We insert the predicted values in the table\n",
    "supernova_predict['Prediction Ridge'] = supernova_ridge.predict(x)\n",
    "supernova_ridge.params #Here we have the coefficients for the parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Decision Tree Regressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we are going to try the DecisionTreeRegressor for several values of max_depth. We would choose the one that reduce the MSE for the values to predict  5,10,15,25,30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSEold=10000\n",
    "x_tree = ['Magnitude','Prediction OLS','Prediction Ridge','Prediction Tree']\n",
    "for i in range(2,30):\n",
    "    for j in range(100):\n",
    "        reg_rtree = DecisionTreeRegressor(max_depth=i).fit(supernova_train.drop('Magnitude',1), supernova_train['Magnitude'])\n",
    "        x_pred = reg_rtree.predict(supernova_predict.drop(x_tree,1))\n",
    "        MSEnew = mean_squared_error(supernova_predict['Magnitude'],x_pred)\n",
    "        if (MSEnew<MSEold):\n",
    "            MSEold = MSEnew\n",
    "            bestreg_rtree=reg_rtree\n",
    "            #We insert the predicted values in the table\n",
    "            supernova_predict['Prediction Tree'] = x_pred\n",
    "            max_depth=i\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "max_depth = 8\nMSE= 0.6280886000000001\n"
    }
   ],
   "source": [
    "print('max_depth =',max_depth)\n",
    "print('MSE=',MSEold)\n",
    "#Here we "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our max_depth for this case is 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Errors and importance features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have our three models, the OLS, the ridge with alpha=0.15 and the decission tree regressor with max_depth=7. Now we can se the predicted values for wach model in the next table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            E1        E2        E3        E4        E5        E6        E7  \\\nSN5   0.481631 -0.794486 -0.183682  1.559922 -0.569026  0.377266 -0.855366   \nSN10 -1.673576 -0.780025 -0.146156 -0.517614  0.271401 -0.160014  0.713097   \nSN15  1.496996  2.484078 -1.995814 -1.805006  0.405950  2.723178  2.301427   \nSN25  0.770707  0.345884  0.322925  3.186758  1.079697 -0.785799 -1.095863   \nSN30  1.218208  0.268414 -0.191582  0.191927  1.959284  0.415791 -0.901374   \n\n            E8        E9       E10  Magnitude  Prediction OLS  \\\nSN5  -1.565895 -1.502760 -1.049453     -3.746       -1.847282   \nSN10 -0.199871 -0.261702 -0.214794      0.576        1.130292   \nSN15  0.820211  0.386363  0.572339      3.103        1.862804   \nSN25 -0.282661  0.691219  1.674325     -2.833       -0.268837   \nSN30 -0.880912 -0.928451  0.062435     -2.092       -1.395568   \n\n      Prediction Ridge  Prediction Tree  \nSN5          -1.854948           -2.279  \nSN10          1.113290            0.903  \nSN15          1.835924            3.075  \nSN25         -0.299624           -3.754  \nSN30         -1.389173           -2.272  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>E1</th>\n      <th>E2</th>\n      <th>E3</th>\n      <th>E4</th>\n      <th>E5</th>\n      <th>E6</th>\n      <th>E7</th>\n      <th>E8</th>\n      <th>E9</th>\n      <th>E10</th>\n      <th>Magnitude</th>\n      <th>Prediction OLS</th>\n      <th>Prediction Ridge</th>\n      <th>Prediction Tree</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>SN5</th>\n      <td>0.481631</td>\n      <td>-0.794486</td>\n      <td>-0.183682</td>\n      <td>1.559922</td>\n      <td>-0.569026</td>\n      <td>0.377266</td>\n      <td>-0.855366</td>\n      <td>-1.565895</td>\n      <td>-1.502760</td>\n      <td>-1.049453</td>\n      <td>-3.746</td>\n      <td>-1.847282</td>\n      <td>-1.854948</td>\n      <td>-2.279</td>\n    </tr>\n    <tr>\n      <th>SN10</th>\n      <td>-1.673576</td>\n      <td>-0.780025</td>\n      <td>-0.146156</td>\n      <td>-0.517614</td>\n      <td>0.271401</td>\n      <td>-0.160014</td>\n      <td>0.713097</td>\n      <td>-0.199871</td>\n      <td>-0.261702</td>\n      <td>-0.214794</td>\n      <td>0.576</td>\n      <td>1.130292</td>\n      <td>1.113290</td>\n      <td>0.903</td>\n    </tr>\n    <tr>\n      <th>SN15</th>\n      <td>1.496996</td>\n      <td>2.484078</td>\n      <td>-1.995814</td>\n      <td>-1.805006</td>\n      <td>0.405950</td>\n      <td>2.723178</td>\n      <td>2.301427</td>\n      <td>0.820211</td>\n      <td>0.386363</td>\n      <td>0.572339</td>\n      <td>3.103</td>\n      <td>1.862804</td>\n      <td>1.835924</td>\n      <td>3.075</td>\n    </tr>\n    <tr>\n      <th>SN25</th>\n      <td>0.770707</td>\n      <td>0.345884</td>\n      <td>0.322925</td>\n      <td>3.186758</td>\n      <td>1.079697</td>\n      <td>-0.785799</td>\n      <td>-1.095863</td>\n      <td>-0.282661</td>\n      <td>0.691219</td>\n      <td>1.674325</td>\n      <td>-2.833</td>\n      <td>-0.268837</td>\n      <td>-0.299624</td>\n      <td>-3.754</td>\n    </tr>\n    <tr>\n      <th>SN30</th>\n      <td>1.218208</td>\n      <td>0.268414</td>\n      <td>-0.191582</td>\n      <td>0.191927</td>\n      <td>1.959284</td>\n      <td>0.415791</td>\n      <td>-0.901374</td>\n      <td>-0.880912</td>\n      <td>-0.928451</td>\n      <td>0.062435</td>\n      <td>-2.092</td>\n      <td>-1.395568</td>\n      <td>-1.389173</td>\n      <td>-2.272</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "#Let's see the values for each model\n",
    "supernova_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the MSE for the predicted values of 5,10,15,25 and 30 in each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MSE_OLS = 2.502080910743422\nMSE_RID = 2.4764398828020155\nMSE_Tree = 0.6280886000000001\n"
    }
   ],
   "source": [
    "MSE_OLS=mean_squared_error(supernova_predict['Magnitude'],supernova_predict['Prediction OLS'])\n",
    "MSE_RID=mean_squared_error(supernova_predict['Magnitude'],supernova_predict['Prediction Ridge'])\n",
    "MSE_Tree=mean_squared_error(supernova_predict['Magnitude'],supernova_predict['Prediction Tree'])\n",
    "print('MSE_OLS =',MSE_OLS)\n",
    "print('MSE_RID =',MSE_RID)\n",
    "print('MSE_Tree =',MSE_Tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First question-Notice that:\n",
    "The smallest MSE is for the decission tree regressor model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can see the most important features in each model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:              Magnitude   R-squared:                       0.819\nModel:                            OLS   Adj. R-squared:                  0.741\nMethod:                 Least Squares   F-statistic:                     10.42\nDate:                Thu, 30 Jul 2020   Prob (F-statistic):           2.19e-06\nTime:                        14:47:23   Log-Likelihood:                -39.950\nNo. Observations:                  34   AIC:                             101.9\nDf Residuals:                      23   BIC:                             118.7\nDf Model:                          10                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.1469      0.163      0.899      0.378      -0.191       0.485\nE1            -0.5250      0.364     -1.444      0.162      -1.277       0.227\nE2             0.5764      0.485      1.188      0.247      -0.427       1.580\nE3            -0.0973      0.516     -0.188      0.852      -1.166       0.971\nE4            -0.0339      0.466     -0.073      0.943      -0.997       0.929\nE5             0.0383      0.328      0.117      0.908      -0.640       0.717\nE6            -0.3558      0.621     -0.573      0.572      -1.641       0.929\nE7             0.7712      0.702      1.099      0.283      -0.681       2.223\nE8            -0.2718      0.644     -0.422      0.677      -1.603       1.060\nE9             0.5819      0.833      0.699      0.492      -1.140       2.304\nE10           -0.0155      0.504     -0.031      0.976      -1.058       1.028\n==============================================================================\nOmnibus:                        2.276   Durbin-Watson:                   1.784\nProb(Omnibus):                  0.320   Jarque-Bera (JB):                1.251\nSkew:                           0.049   Prob(JB):                        0.535\nKurtosis:                       2.065   Cond. No.                         17.3\n==============================================================================\n\nWarnings:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\"\"\"",
      "text/html": "<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>        <td>Magnitude</td>    <th>  R-squared:         </th> <td>   0.819</td>\n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.741</td>\n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   10.42</td>\n</tr>\n<tr>\n  <th>Date:</th>             <td>Thu, 30 Jul 2020</td> <th>  Prob (F-statistic):</th> <td>2.19e-06</td>\n</tr>\n<tr>\n  <th>Time:</th>                 <td>14:47:23</td>     <th>  Log-Likelihood:    </th> <td> -39.950</td>\n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>    34</td>      <th>  AIC:               </th> <td>   101.9</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>    23</td>      <th>  BIC:               </th> <td>   118.7</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>   \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th> <td>    0.1469</td> <td>    0.163</td> <td>    0.899</td> <td> 0.378</td> <td>   -0.191</td> <td>    0.485</td>\n</tr>\n<tr>\n  <th>E1</th>    <td>   -0.5250</td> <td>    0.364</td> <td>   -1.444</td> <td> 0.162</td> <td>   -1.277</td> <td>    0.227</td>\n</tr>\n<tr>\n  <th>E2</th>    <td>    0.5764</td> <td>    0.485</td> <td>    1.188</td> <td> 0.247</td> <td>   -0.427</td> <td>    1.580</td>\n</tr>\n<tr>\n  <th>E3</th>    <td>   -0.0973</td> <td>    0.516</td> <td>   -0.188</td> <td> 0.852</td> <td>   -1.166</td> <td>    0.971</td>\n</tr>\n<tr>\n  <th>E4</th>    <td>   -0.0339</td> <td>    0.466</td> <td>   -0.073</td> <td> 0.943</td> <td>   -0.997</td> <td>    0.929</td>\n</tr>\n<tr>\n  <th>E5</th>    <td>    0.0383</td> <td>    0.328</td> <td>    0.117</td> <td> 0.908</td> <td>   -0.640</td> <td>    0.717</td>\n</tr>\n<tr>\n  <th>E6</th>    <td>   -0.3558</td> <td>    0.621</td> <td>   -0.573</td> <td> 0.572</td> <td>   -1.641</td> <td>    0.929</td>\n</tr>\n<tr>\n  <th>E7</th>    <td>    0.7712</td> <td>    0.702</td> <td>    1.099</td> <td> 0.283</td> <td>   -0.681</td> <td>    2.223</td>\n</tr>\n<tr>\n  <th>E8</th>    <td>   -0.2718</td> <td>    0.644</td> <td>   -0.422</td> <td> 0.677</td> <td>   -1.603</td> <td>    1.060</td>\n</tr>\n<tr>\n  <th>E9</th>    <td>    0.5819</td> <td>    0.833</td> <td>    0.699</td> <td> 0.492</td> <td>   -1.140</td> <td>    2.304</td>\n</tr>\n<tr>\n  <th>E10</th>   <td>   -0.0155</td> <td>    0.504</td> <td>   -0.031</td> <td> 0.976</td> <td>   -1.058</td> <td>    1.028</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td> 2.276</td> <th>  Durbin-Watson:     </th> <td>   1.784</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.320</td> <th>  Jarque-Bera (JB):  </th> <td>   1.251</td>\n</tr>\n<tr>\n  <th>Skew:</th>          <td> 0.049</td> <th>  Prob(JB):          </th> <td>   0.535</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 2.065</td> <th>  Cond. No.          </th> <td>    17.3</td>\n</tr>\n</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "#For the OLS model, here we can look for the coefficients.\n",
    "supernova_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([ 0.14623719, -0.52533127,  0.57661627, -0.10647332, -0.0411362 ,\n        0.03182501, -0.36276359,  0.74191783, -0.21686775,  0.53432215,\n       -0.00714745])"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "#For the Ridge model, here we can look for the coefficients.\n",
    "supernova_ridge.params\n",
    "#Here the first value is the coefficient for the constant, so we have to look in the other components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  variable_name  importance\n7            E8    0.571369\n6            E7    0.218551\n3            E4    0.066892\n2            E3    0.040843\n1            E2    0.040049\n8            E9    0.031287\n5            E6    0.014144\n0            E1    0.013006\n9           E10    0.002548\n4            E5    0.001312",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>variable_name</th>\n      <th>importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>E8</td>\n      <td>0.571369</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>E7</td>\n      <td>0.218551</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>E4</td>\n      <td>0.066892</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>E3</td>\n      <td>0.040843</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>E2</td>\n      <td>0.040049</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>E9</td>\n      <td>0.031287</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>E6</td>\n      <td>0.014144</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>E1</td>\n      <td>0.013006</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>E10</td>\n      <td>0.002548</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>E5</td>\n      <td>0.001312</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "#For the decission tree regressor model, here we can look for the coefficients.\n",
    "feat_imps = bestreg_rtree.feature_importances_\n",
    "feat_imp_df = pd.DataFrame({'variable_name': supernova_train.drop('Magnitude',1).columns , 'importance': feat_imps}) \\\n",
    "                .sort_values('importance', ascending=False)\n",
    "feat_imp_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second question-We need to notice that:\n",
    "For each model the most 4 important features  are:\n",
    "\n",
    "- OLS model -> E7,E9,E2,E1\n",
    "- Ridge model-> E7,E2,E9,E1\n",
    "- Tree model -> E8,E7,E4,E3\n",
    "\n",
    "in their respective order, from the most to the less important\n",
    "\n",
    "__Coefficients in OLS:__\n",
    "- E7->0.7712\n",
    "- E9->0.5819\n",
    "- E2->0.5764\n",
    "- E1->-0.5250\n",
    "\n",
    "__Coefficients in Ridge:__\n",
    "- E7->0.74191783\n",
    "- E2-> 0.57661627\n",
    "- E9-> 0.53432215\n",
    "- E1->-0.52533127\n",
    "\n",
    "__Importance in Tree:__\n",
    "- E8->0.572898\n",
    "- E7->0.217316\n",
    "- E4->0.067275\n",
    "- E3->0.045333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try with the most important components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to improve our models just taking the __two most important components__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Knowing the previous information, we take just the first two most important components for each model\n",
    "#For OLS we use E7 and E9\n",
    "#For Ridge E7 and E2\n",
    "#For Tree E8 and E7\n",
    "NewtryOLS_train = supernova_train.drop(['E1','E2','E3','E4','E5','E6','E8','E10'],1)\n",
    "NewtryOLS_predict = supernova_predict.drop(['E1','E2','E3','E4','E5','E6','E8','E10','Prediction OLS','Prediction Ridge','Prediction Tree'],1)\n",
    "NewtryRidge_train = supernova_train.drop(['E1','E3','E4','E5','E6','E8','E9','E10'],1)\n",
    "NewtryRidge_predict = supernova_predict.drop(['E1','E3','E4','E5','E6','E8','E9','E10','Prediction OLS','Prediction Ridge','Prediction Tree'],1)\n",
    "NewtryTree_train = supernova_train.drop(['E1','E2','E3','E4','E5','E6','E9','E10'],1)\n",
    "NewtryTree_predict = supernova_predict.drop(['E1','E2','E3','E4','E5','E6','E9','E10','Prediction OLS','Prediction Ridge','Prediction Tree'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our new model for OLSE\n",
    "x = add_constant(NewtryOLS_predict.drop(['Magnitude'],axis=1))\n",
    "x_cols = ['E7','E9']\n",
    "supernova_ols = OLS(NewtryOLS_train['Magnitude'], add_constant(NewtryOLS_train[x_cols])).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our new model for Ridge\n",
    "x_cols = ['E2','E7']\n",
    "supernova_skR = RidgeCV(alphas=[0.09,0.1,0.11,0.12,0.13,0.14,0.15]).fit(add_constant(NewtryRidge_train[x_cols]),NewtryRidge_train['Magnitude'])\n",
    "model_cv = supernova_skR.fit(add_constant(NewtryRidge_train[x_cols]),NewtryRidge_train['Magnitude'])\n",
    "alp=model_cv.alpha_\n",
    "supernova_ridge = linear_model.OLS(NewtryRidge_train['Magnitude'], \n",
    "                                   add_constant(NewtryRidge_train[x_cols])).fit_regularized(alpha=alp/NewtryRidge_train.shape[0], L1_wt=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our new model for Decission Tree Regressor\n",
    "MSEold=10000\n",
    "x_tree = ['Magnitude']\n",
    "for i in range(2,30):\n",
    "    for j in range(100):\n",
    "        reg_rtree = DecisionTreeRegressor(max_depth=i).fit(NewtryTree_train.drop('Magnitude',1), NewtryTree_train['Magnitude'])\n",
    "        x_pred = reg_rtree.predict(NewtryTree_predict.drop('Magnitude',1))\n",
    "        MSEnew = mean_squared_error(NewtryTree_predict['Magnitude'],x_pred)\n",
    "        if (MSEnew<MSEold):\n",
    "            MSEold = MSEnew\n",
    "            bestreg_rtree_new=reg_rtree\n",
    "            max_depth_new=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "max_depth = 9\nMSE= 0.18595240000000007\n"
    }
   ],
   "source": [
    "print('max_depth =',max_depth_new)\n",
    "print('MSE=',MSEold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MSE_OLS_new = 1.7979628868739794\nMSE_RID_new = 5.096587786339689\nMSE_Tree_new = 0.18595240000000007\n"
    }
   ],
   "source": [
    "MSE_OLS_new=mean_squared_error(NewtryOLS_predict['Magnitude'], supernova_ols.predict(x))\n",
    "MSE_RID_new=mean_squared_error(NewtryRidge_predict['Magnitude'],supernova_ridge.predict(x))\n",
    "MSE_Tree_new=mean_squared_error(NewtryTree_predict['Magnitude'],bestreg_rtree_new.predict(NewtryTree_predict.drop('Magnitude',1)))\n",
    "print('MSE_OLS_new =',MSE_OLS_new)\n",
    "print('MSE_RID_new =',MSE_RID_new)\n",
    "print('MSE_Tree_new =',MSE_Tree_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we can see that:\n",
    "There was and improvement for the OLS and Tree models. Nevertheless, the ridge model goes worse than the ridge model with all the parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}